TODO: svakheter, hvordan gjøre bedre? hva er mitt bidrag?  \\

This chapter presents possible future works and concludes this thesis.

\section{Thesis Contribution}
This thesis presents a program that visualize collected data both spatially on a map and by traditional graphs. The information is presented by category and with multiple tools to help with investigative analysis. Tools like moving, zooming in and out on graph assets, capturing graph state, adjusting subplot parameters, comparison of graphs, querying graphs and map visualisation. The program is a prototype of what an automated collection of multi-source spatial information for emergency management may look like, it is also modular and scalable making future work possible by integrating new sources from other agencies.

\section{Future works}
The program contains some bugs and inefficient solutions. Ameliorating these algorithm requires more work than what is this thesis's time scope.

\subsection{Known bugs and other imperfect implementations}
One known negligent solution is the algorithms in the program of double\_y\_graphs.py where redundant calculations take place. Fixing this would make the program gui.py slightly faster and be more structural preferable.
The program NIPH\_frame.py serves the function to draw two graphs on the same x axis, this was however only accomplished on a weekly temporal resolution. Some graphs have a higher resolution like for instance Twitter, but the data is still aggregated into a weekly resolution in the program. Writing algorithms that would support an hourly or weekly resolution became outside of the time scope of this thesis. Future work may focus on being able to compare different resolutions as this would offer a better comparison of the different datasets. 
Another known bug is that the buttons panel disappear when the window size is not big enough.

The NPRA hourly dataset GUI implementation is missing the option to choose from different traffic registration stations.

Some functions in the different modules both in the backend and in the frontend are redundant, a better overall structure would be to collect these often used functions in their own utility module. An example of this may be the drawing of graphs in the backend. Having a draw module that only draws whatever the different modules require would serve as a uniform utility tool.

\subsection{Google static map}
As discussed in the previous chapter clustering traffic registration stations would solve the maximum URL problem. When presented with a map that shows all of Norway instead of showing each traffic registration stations one could cluster them together by proximity, and when zooming in present an even more fine tuned clustering until the zoom level is sufficient enough to show all of the traffic registration stations on that level. This is already a standard way of presenting spatial data as seen in the NPRA's online roadmap\cite{vegkart} when selecting multiple elements. Further standardizing colors and sizes would significantly save url length, the thought behind different sizes and colors was only intended on a very zoomed in level and is not necessarily needed when showing clusters. The url size problem would also completely vanish if taken a Node/Javascript approach instead. 

\subsection{Database}
At the very end of the time scope of this thesis it became obvious that the backend's data should have been implemented in some sort of a database in order to speed up the process of reading and extracting exact information. Data filtering is the process of refining data sets for relevant user information, different filters can be tailored for different needs. Filtering becomes particularly useful in the NPRA's hourly dataset, an example would be to filter out the different vehicle lanes available, this would on average make the algorithm two times faster. In order to take advantage of data filtering and indexing the data would have to be implemented in a database. A possible more optimal solution would be to rewrite the entire project in Node/Javascript and mount the backend's data in a server such that it is available to the frontend modules.




\section{Conclusion}
Automated collection of multi-source spatial information for emergency management such as creating a responsive real-time reactionary system for influenza is feasible.
The automation part may not become practical for years to come as the Norwegian public API infrastructure is notwithstanding at the current time. However collecting data manually is still a reasonable effort. Implementing more relevant sources should also be a priority, as well as collecting spatial data for specific regions of Norway. 
This thesis shows that an automated collection of multi-source spatial information for emergency management is achievable, however, this would require much more resources than a single master student can offer. Further development of such a program, be that for influenza purposes or other, would be highly ethical as it would be an exceptional aid to ameliorate the purposed predicament. Efforts to further support data collection of citizen behaviour on a macro scale should be initiated such as to encourage additional endeavours.

This potential technology presented is merely a utility information tool that could be used or misused. An example of exploit would be the Chinese Sesame 'Social credit system' program\cite{meissner2017china}\cite{china_botsman}\cite{china_wiki}, where a propaganda game rating citizens with 'Sesame credits' on their lives and judging them according to their 'trustworthiness' and 'social integrity' of their individual behaviour. Behaviour such as local and online purchases, real-time location, who friends and family are and what they do, the content of leisure and payment of bills. This mass surveillance tool uses big data analysis technology, and in contradiction to official intents acts as an oppressive system punishing its subjects. Examples of punishment are flight bans limiting movement, excluding parent's children from enrolling in private schools, slow internet access, exclusion from certain jobs, exclusion from hotel services, and forced registration on a public blacklist. The Sesame credit system also works for businesses in their own way.

This thesis does not endorse or suggest oppressive mass surveillance. It is considerate to contemplate ethical values when developing systems that rely on public information extraction, taking care to not be reckless with sensitive data by insincere or cynical means, and having a genuine interest in the well-being of the public. This is the reason the NIPH ILI daily data from Oslo and Bergen are omitted in the delivery of this thesis, as the possible information derived might be too delicate. Norway already has a government agency installed protecting such concerns\cite{datatilsynet}, albeit new technologies and usage are revealed continuously it is important to have an ongoing update on such policies.


TODO: synsing om marked som kan utnyttes, utfording å hente data






































